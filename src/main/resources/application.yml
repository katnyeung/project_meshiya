server:
  port: 8080

spring:
  data:
    redis:
      host: localhost
      port: 6379
      timeout: 2000ms
  
  websocket:
    allowed-origins: "http://localhost:3000,http://127.0.0.1:3000"

meshiya:
  diner:
    max-seats: 8
    ai-response-delay: 3000
    max-context-messages: 20
  user:
    timeout:
      minutes: 10  # Users will be logged out after 10 minutes of inactivity

# LLM Configuration
llm:
  # Chat/Conversation configuration - Switchable providers
  chat:
    provider: perplexity  # Options: perplexity, openai, ollama
    api:
      url: https://api.perplexity.ai/chat/completions
      key: ${PERPLEXITY_API_KEY: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}  # Set your API key here or in environment
    model: sonar  # Provider-specific model name
    timeout: 30000
  
  # Order processing configuration - Switchable providers (optimized for fast, structured responses)
  order:
    provider: perplexity  # Options: perplexity, openai, ollama
    api:
      url: https://api.perplexity.ai/chat/completions
      key: ${PERPLEXITY_API_KEY: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}  # Set your API key here or in environment
    model: sonar  # Provider-specific model name
    timeout: 15000

# Swagger/OpenAPI Configuration
springdoc:
  api-docs:
    path: /api-docs
  swagger-ui:
    path: /swagger-ui.html
    enabled: true
    operationsSorter: method
    tagsSorter: alpha
    tryItOutEnabled: true
  show-actuator: false